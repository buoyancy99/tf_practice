{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f0a67b8ec50>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_image = mnist.train.next_batch(1)[0]\n",
    "sample_image = sample_image.reshape([28, 28])\n",
    "plt.imshow(sample_image, cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator(X, name=\"d\",reuse=False):\n",
    "    with tf.variable_scope(name, reuse=reuse):\n",
    "        with tf.variable_scope(\"conv1\"):\n",
    "            w1 = tf.get_variable('w', [5,5,1,32], initializer=tf.truncated_normal_initializer(stddev = 0.02))\n",
    "            b1 = tf.get_variable('b', [32], initializer=tf.constant_initializer(0.01))\n",
    "            a1 = tf.nn.relu(tf.nn.conv2d(X, filter=w1, strides=[1,1,1,1], padding='SAME') + b1)\n",
    "            p1 = tf.nn.avg_pool(a1, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "        \n",
    "        with tf.variable_scope(\"conv2\"):\n",
    "            w2 = tf.get_variable('w', [5,5,32,64], initializer=tf.truncated_normal_initializer(stddev = 0.02))\n",
    "            b2 = tf.get_variable('b', [64], initializer=tf.constant_initializer(0.01))\n",
    "            a2 = tf.nn.relu(tf.nn.conv2d(p1, filter=w2, strides=[1,1,1,1], padding='SAME') + b2)\n",
    "            p2 = tf.nn.avg_pool(a2, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "            p2 = tf.reshape(p2, [-1, 7 * 7 * 64])\n",
    "        \n",
    "        with tf.variable_scope(\"fc1\"):\n",
    "            w3 = tf.get_variable('w', [7*7*64, 1024], initializer=tf.truncated_normal_initializer(stddev = 0.02))\n",
    "            b3 = tf.get_variable('b', [1024], initializer=tf.constant_initializer(0.01))\n",
    "            a3 = tf.nn.relu(tf.matmul(p2, w3) + b3)\n",
    "        \n",
    "        with tf.variable_scope(\"fc2\"):\n",
    "            w4 = tf.get_variable('w', [1024, 1], initializer=tf.truncated_normal_initializer(stddev = 0.02))\n",
    "            b4 = tf.get_variable('b', [1], initializer=tf.constant_initializer(0.01))\n",
    "            a4 = tf.nn.relu(tf.matmul(a3, w4) + b4)\n",
    "        \n",
    "    return a4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(X, name='g',reuse=False):\n",
    "    dim = int(X.shape[-1])\n",
    "    \n",
    "    with tf.variable_scope(name, reuse=reuse):\n",
    "        with tf.variable_scope(\"fc1\"):\n",
    "            w1 = tf.get_variable('w', [dim, 3136], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "            b1 = tf.get_variable('b', [3136], initializer=tf.truncated_normal_initializer(stddev=0.01))\n",
    "            z1 = tf.matmul(X, w1) + b1\n",
    "            z1 = tf.reshape(z1, [-1, 56, 56, 1])\n",
    "            z1 = tf.contrib.layers.batch_norm(z1, epsilon=1e-5, scope='bn')\n",
    "            a1 = tf.nn.relu(z1)\n",
    "\n",
    "        # Generate 50 features\n",
    "        with tf.variable_scope(\"conv1\"):\n",
    "            w2 = tf.get_variable('w', [3, 3, 1, dim/2], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "            b2 = tf.get_variable('b', [dim/2], initializer=tf.truncated_normal_initializer(stddev=0.01))\n",
    "            z2 = tf.nn.conv2d(a1, w2, strides=[1, 2, 2, 1], padding='SAME') + b2\n",
    "            z2 = tf.contrib.layers.batch_norm(z2, epsilon=1e-5, scope='bn')\n",
    "            a2 = tf.nn.relu(z2)\n",
    "            a2 = tf.image.resize_images(a2, [56, 56])\n",
    "\n",
    "        with tf.variable_scope(\"conv2\"):\n",
    "            w3 = tf.get_variable('w', [3, 3, dim/2, dim/4], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "            b3 = tf.get_variable('b', [dim/4], initializer=tf.truncated_normal_initializer(stddev=0.01))\n",
    "            z3 = tf.nn.conv2d(a2, w3, strides=[1, 2, 2, 1], padding='SAME') + b3\n",
    "            z3 = tf.contrib.layers.batch_norm(z3, epsilon=1e-5, scope='bn')\n",
    "            a3 = tf.nn.relu(z3)\n",
    "            a3 = tf.image.resize_images(a3, [56, 56])\n",
    "            \n",
    "        with tf.variable_scope(\"conv3\"):\n",
    "            w4 = tf.get_variable('w', [1, 1, dim/4, 1], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "            b4 = tf.get_variable('b', [1], initializer=tf.truncated_normal_initializer(stddev=0.01))\n",
    "            z4 = tf.nn.conv2d(a3, w4, strides=[1, 2, 2, 1], padding='SAME') + b4\n",
    "            a4 = tf.sigmoid(z4)\n",
    "\n",
    "    return a4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "batch_size = 50\n",
    "seed_dim = 100\n",
    "seed_placeholder = tf.placeholder(tf.float32, [None, seed_dim], name='seed_placeholder')\n",
    "real_placeholder = tf.placeholder(tf.float32, shape = [None,28,28,1], name='real_placeholder') \n",
    "G = generator(seed_placeholder)\n",
    "Dr = discriminator(real_placeholder) \n",
    "Df = discriminator(G, reuse=True)\n",
    "\n",
    "d_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=Dr, labels = tf.ones_like(Dr)))\n",
    "d_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=Df, labels = tf.zeros_like(Df)))\n",
    "g_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=Df, labels = tf.ones_like(Df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = tf.trainable_variables()\n",
    "d_params = [p for p in params if 'd/' in p.name]\n",
    "g_params = [p for p in params if 'g/' in p.name]\n",
    "\n",
    "d_trainer_fake = tf.train.AdamOptimizer(0.0003).minimize(d_loss_fake, var_list=d_params)\n",
    "d_trainer_real = tf.train.AdamOptimizer(0.0003).minimize(d_loss_real, var_list=d_params)\n",
    "g_trainer = tf.train.AdamOptimizer(0.0001).minimize(g_loss, var_list=g_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "tf.summary.scalar('Generator_loss', g_loss)\n",
    "tf.summary.scalar('Discriminator_loss_real', d_loss_real)\n",
    "tf.summary.scalar('Discriminator_loss_fake', d_loss_fake)\n",
    "\n",
    "images_for_tensorboard = generator(seed_placeholder, reuse=True)\n",
    "tf.summary.image('Generated_images', images_for_tensorboard, 5)\n",
    "merged = tf.summary.merge_all()\n",
    "logdir = \"tensorboard/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") + \"/\"\n",
    "writer = tf.summary.FileWriter(logdir, sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "batch_size = 2\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# Pre-train discriminator\n",
    "for i in range(300):\n",
    "    print(i)\n",
    "    seed_batch = np.random.normal(0, 1, size=[batch_size, seed_dim])\n",
    "    real_image_batch = mnist.train.next_batch(batch_size)[0].reshape([batch_size, 28, 28, 1])\n",
    "    _, _, dLossReal, dLossFake = sess.run([d_trainer_real, d_trainer_fake, d_loss_real, d_loss_fake],\n",
    "                                           {real_placeholder: real_image_batch, seed_placeholder: seed_batch})\n",
    "\n",
    "    if(i % 100 == 0):\n",
    "        print(\"dLossReal:\", dLossReal, \"dLossFake:\", dLossFake)\n",
    "\n",
    "# # Train generator and discriminator together\n",
    "# for i in range(100000):\n",
    "#     real_image_batch = mnist.train.next_batch(batch_size)[0].reshape([batch_size, 28, 28, 1])\n",
    "#     seed_batch = np.random.normal(0, 1, size=[batch_size, seed_dim])\n",
    "\n",
    "#     # Train discriminator on both real and fake images\n",
    "#     _, _, dLossReal, dLossFake = sess.run([d_trainer_real, d_trainer_fake, d_loss_real, d_loss_fake],\n",
    "#                                            {real_placeholder: real_image_batch, seed_placeholder: seed_batch})\n",
    "\n",
    "#     # Train generator\n",
    "#     seed_batch = np.random.normal(0, 1, size=[batch_size, seed_dim])\n",
    "#     _ = sess.run(g_trainer, feed_dict={seed_placeholder: seed_batch})\n",
    "\n",
    "#     if i % 10 == 0:\n",
    "#         # Update TensorBoard with summary statistics\n",
    "#         seed_batch = np.random.normal(0, 1, size=[batch_size, seed_dim])\n",
    "#         summary = sess.run(merged, {seed_placeholder: seed_batch, real_placeholder: real_image_batch})\n",
    "#         writer.add_summary(summary, i)\n",
    "\n",
    "#     if i % 100 == 0:\n",
    "#         # Every 100 iterations, show a generated image\n",
    "#         print(\"Iteration:\", i, \"at\", datetime.datetime.now())\n",
    "#         seed_batch = np.random.normal(0, 1, size=[1, seed_dim])\n",
    "#         generated_images = generator(seed_placeholder, 1, seed_dim)\n",
    "#         images = sess.run(generated_images, {seed_placeholder: seed_batch})\n",
    "#         plt.imshow(images[0].reshape([28, 28]), cmap='Greys')\n",
    "#         plt.show()\n",
    "\n",
    "#         # Show discriminator's estimate\n",
    "#         im = images[0].reshape([1, 28, 28, 1])\n",
    "#         result = discriminator(real_placeholder)\n",
    "#         estimate = sess.run(result, {real_placeholder: im})\n",
    "#         print(\"Estimate:\", estimate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
