{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fd77b34fa58>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_image = mnist.train.next_batch(1)[0]\n",
    "sample_image = sample_image.reshape([28, 28])\n",
    "plt.imshow(sample_image, cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator(X, name=\"d\",reuse=False):\n",
    "    with tf.variable_scope(name, reuse=reuse):\n",
    "        with tf.variable_scope(\"conv1\"):\n",
    "            w1 = tf.get_variable('w', [5,5,1,32], initializer=tf.truncated_normal_initializer(stddev = 0.02))\n",
    "            b1 = tf.get_variable('b', [32], initializer=tf.constant_initializer(0.01))\n",
    "            a1 = tf.nn.relu(tf.nn.conv2d(X, filter=w1, strides=[1,1,1,1], padding='SAME') + b1)\n",
    "            p1 = tf.nn.avg_pool(a1, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "        \n",
    "        with tf.variable_scope(\"conv2\"):\n",
    "            w2 = tf.get_variable('w', [5,5,32,64], initializer=tf.truncated_normal_initializer(stddev = 0.02))\n",
    "            b2 = tf.get_variable('b', [64], initializer=tf.constant_initializer(0.01))\n",
    "            a2 = tf.nn.relu(tf.nn.conv2d(p1, filter=w2, strides=[1,1,1,1], padding='SAME') + b2)\n",
    "            p2 = tf.nn.avg_pool(a2, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "            p2 = tf.reshape(p2, [-1, 7 * 7 * 64])\n",
    "        \n",
    "        with tf.variable_scope(\"fc1\"):\n",
    "            w3 = tf.get_variable('w', [7*7*64, 1024], initializer=tf.truncated_normal_initializer(stddev = 0.02))\n",
    "            b3 = tf.get_variable('b', [1024], initializer=tf.constant_initializer(0.01))\n",
    "            a3 = tf.nn.relu(tf.matmul(p2, w3) + b3)\n",
    "        \n",
    "        with tf.variable_scope(\"fc2\"):\n",
    "            w4 = tf.get_variable('w', [1024, 1], initializer=tf.truncated_normal_initializer(stddev = 0.02))\n",
    "            b4 = tf.get_variable('b', [1], initializer=tf.constant_initializer(0.01))\n",
    "            a4 = tf.nn.relu(tf.matmul(a3, w4) + b4)\n",
    "        \n",
    "    return a4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(X, name='g',reuse=False):\n",
    "    dim = int(X.shape[-1])\n",
    "    \n",
    "    with tf.variable_scope(name, reuse=reuse):\n",
    "        with tf.variable_scope(\"fc1\"):\n",
    "            w1 = tf.get_variable('w', [dim, 3136], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "            b1 = tf.get_variable('b', [3136], initializer=tf.truncated_normal_initializer(stddev=0.01))\n",
    "            z1 = tf.matmul(X, w1) + b1\n",
    "            z1 = tf.reshape(z1, [-1, 56, 56, 1])\n",
    "            z1 = tf.contrib.layers.batch_norm(z1, epsilon=1e-5, scope='bn')\n",
    "            a1 = tf.nn.relu(z1)\n",
    "\n",
    "        # Generate 50 features\n",
    "        with tf.variable_scope(\"conv1\"):\n",
    "            w2 = tf.get_variable('w', [3, 3, 1, dim/2], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "            b2 = tf.get_variable('b', [dim/2], initializer=tf.truncated_normal_initializer(stddev=0.01))\n",
    "            z2 = tf.nn.conv2d(a1, w2, strides=[1, 2, 2, 1], padding='SAME') + b2\n",
    "            z2 = tf.contrib.layers.batch_norm(z2, epsilon=1e-5, scope='bn')\n",
    "            a2 = tf.nn.relu(z2)\n",
    "            a2 = tf.image.resize_images(a2, [56, 56])\n",
    "\n",
    "        with tf.variable_scope(\"conv2\"):\n",
    "            w3 = tf.get_variable('w', [3, 3, dim/2, dim/4], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "            b3 = tf.get_variable('b', [dim/4], initializer=tf.truncated_normal_initializer(stddev=0.01))\n",
    "            z3 = tf.nn.conv2d(a2, w3, strides=[1, 2, 2, 1], padding='SAME') + b3\n",
    "            z3 = tf.contrib.layers.batch_norm(z3, epsilon=1e-5, scope='bn')\n",
    "            a3 = tf.nn.relu(z3)\n",
    "            a3 = tf.image.resize_images(a3, [56, 56])\n",
    "            \n",
    "        with tf.variable_scope(\"conv3\"):\n",
    "            w4 = tf.get_variable('w', [1, 1, dim/4, 1], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "            b4 = tf.get_variable('b', [1], initializer=tf.truncated_normal_initializer(stddev=0.01))\n",
    "            z4 = tf.nn.conv2d(a3, w4, strides=[1, 2, 2, 1], padding='SAME') + b4\n",
    "            a4 = tf.sigmoid(z4)\n",
    "\n",
    "    return a4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "batch_size = 50\n",
    "seed_dim = 100\n",
    "seed_placeholder = tf.placeholder(tf.float32, [None, seed_dim], name='seed_placeholder')\n",
    "real_placeholder = tf.placeholder(tf.float32, shape = [None,28,28,1], name='real_placeholder') \n",
    "G = generator(seed_placeholder)\n",
    "Dr = discriminator(real_placeholder) \n",
    "Df = discriminator(G, reuse=True)\n",
    "\n",
    "d_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=Dr, labels = tf.ones_like(Dr)))\n",
    "d_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=Df, labels = tf.zeros_like(Df)))\n",
    "g_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=Df, labels = tf.ones_like(Df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = tf.trainable_variables()\n",
    "d_params = [p for p in params if 'd/' in p.name]\n",
    "g_params = [p for p in params if 'g/' in p.name]\n",
    "\n",
    "d_trainer_fake = tf.train.AdamOptimizer(0.0003).minimize(d_loss_fake, var_list=d_params)\n",
    "d_trainer_real = tf.train.AdamOptimizer(0.0003).minimize(d_loss_real, var_list=d_params)\n",
    "g_trainer = tf.train.AdamOptimizer(0.0001).minimize(g_loss, var_list=g_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "tf.summary.scalar('Generator_loss', g_loss)\n",
    "tf.summary.scalar('Discriminator_loss_real', d_loss_real)\n",
    "tf.summary.scalar('Discriminator_loss_fake', d_loss_fake)\n",
    "\n",
    "images_for_tensorboard = generator(seed_placeholder, reuse=True)\n",
    "tf.summary.image('Generated_images', images_for_tensorboard, 5)\n",
    "merged = tf.summary.merge_all()\n",
    "logdir = \"tensorboard/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") + \"/\"\n",
    "writer = tf.summary.FileWriter(logdir, sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "batch_size = 2\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# Pre-train discriminator\n",
    "for i in range(300):\n",
    "    print(i)\n",
    "    seed_batch = np.random.normal(0, 1, size=[batch_size, seed_dim])\n",
    "    real_image_batch = mnist.train.next_batch(batch_size)[0].reshape([batch_size, 28, 28, 1])\n",
    "    _, _, dLossReal, dLossFake = sess.run([d_trainer_real, d_trainer_fake, d_loss_real, d_loss_fake],\n",
    "                                           {real_placeholder: real_image_batch, seed_placeholder: seed_batch})\n",
    "\n",
    "    if(i % 100 == 0):\n",
    "        print(\"dLossReal:\", dLossReal, \"dLossFake:\", dLossFake)\n",
    "\n",
    "# Train generator and discriminator together\n",
    "for i in range(100000):\n",
    "    real_image_batch = mnist.train.next_batch(batch_size)[0].reshape([batch_size, 28, 28, 1])\n",
    "    seed_batch = np.random.normal(0, 1, size=[batch_size, seed_dim])\n",
    "\n",
    "    # Train discriminator on both real and fake images\n",
    "    _, _, dLossReal, dLossFake = sess.run([d_trainer_real, d_trainer_fake, d_loss_real, d_loss_fake],\n",
    "                                           {real_placeholder: real_image_batch, seed_placeholder: seed_batch})\n",
    "\n",
    "    # Train generator\n",
    "    seed_batch = np.random.normal(0, 1, size=[batch_size, seed_dim])\n",
    "    _ = sess.run(g_trainer, feed_dict={seed_placeholder: seed_batch})\n",
    "\n",
    "    if i % 10 == 0:\n",
    "        # Update TensorBoard with summary statistics\n",
    "        seed_batch = np.random.normal(0, 1, size=[batch_size, seed_dim])\n",
    "        summary = sess.run(merged, {seed_placeholder: seed_batch, real_placeholder: real_image_batch})\n",
    "        writer.add_summary(summary, i)\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        # Every 100 iterations, show a generated image\n",
    "        print(\"Iteration:\", i, \"at\", datetime.datetime.now())\n",
    "        seed_batch = np.random.normal(0, 1, size=[1, seed_dim])\n",
    "        generated_images = generator(seed_placeholder, 1, seed_dim)\n",
    "        images = sess.run(generated_images, {seed_placeholder: seed_batch})\n",
    "        plt.imshow(images[0].reshape([28, 28]), cmap='Greys')\n",
    "        plt.show()\n",
    "\n",
    "        # Show discriminator's estimate\n",
    "        im = images[0].reshape([1, 28, 28, 1])\n",
    "        result = discriminator(real_placeholder)\n",
    "        estimate = sess.run(result, {real_placeholder: im})\n",
    "        print(\"Estimate:\", estimate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
